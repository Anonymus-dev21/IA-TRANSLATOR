import streamlit as st
import os
from dotenv import load_dotenv
import google.generativeai as genai
from langdetect import detect


load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")


if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)
else:
    st.error("‚ö†Ô∏è No se encontr√≥ la API Key en el archivo .env.")


def update_translation():
   
    if st.session_state.get("texto") and st.session_state.get("idioma_destino"):
        try:
            idioma_origen = detect(st.session_state.texto)
            prompt = (
                f"Traduce este texto al {st.session_state.idioma_destino}. "
                f"Debe ser claro, preciso y corto, no debes explicar en la respuesta lo que el texto expresa, solo traducirlo explicitamente al idioma que se lo requiere y no  especificar el tema por escrito, solo traducirlo. Manteniendo el contexto: '{st.session_state.contexto}'. "
                f"Tono: {st.session_state.tono}. Texto: {st.session_state.texto}"
            )
            model = genai.GenerativeModel("gemini-1.5-pro-latest")
            response = model.generate_content(prompt)
            st.session_state.traduccion = response.text
        except Exception as e:
            st.session_state.traduccion = f"‚ùå Error al traducir: {e}"

# Interfaz estilo Google Translate / DeepL
st.title("üîÑ Traductor Inteligente")
st.write("Traducci√≥n r√°pida y precisa con contexto.")

col1, col2 = st.columns(2)

# Columna 1 (entrada y contexto) con on_change en cada widget
with col1:
    st.selectbox("Tono", ["Neutro", "Formal", "Informal", "Coloquial"],
                  key="tono", )
    st.text_area("Texto original", height=200, placeholder="Escribe o pega el texto aqu√≠...",
                 key="texto", on_change=update_translation)
    st.text_input("Contexto del mensaje (opcional)",
                  placeholder="Ej: conversaci√≥n de negocios, mensaje personal...",
                  key="contexto", )
 
    if st.button("Generar Traducci√≥n"):
        update_translation()

with col2:
    st.selectbox("Idioma de destino", ["Espa√±ol", "Ingl√©s", "Franc√©s", "Alem√°n", "Coreano", "Italiano", "Portugu√©s", "Chino", "Japon√©s", "Ruso", "√Årabe", "Hindi"],
                  key="idioma_destino", on_change=update_translation)
    st.text_area("Traducci√≥n", value=st.session_state.get('traduccion', ''),
                 height=200, disabled=True, placeholder="La traducci√≥n aparecer√° aqu√≠...")

def es_relacionado_con_lenguaje(texto):
    palabras_clave = [
        "idioma", "traduce", "traducci√≥n", "traduccion", "traducir", "traducido" "ling√º√≠stica",
        "lenguaje", "gram√°tica", "vocabulario", "traduzcas",  "significado",
        "pronunciaci√≥n", "dialecto", "sem√°ntica", "sintaxis",
        "comunicaci√≥n", "escritura", "lectura", "interpretaci√≥n",
        "palabra", "frase", "oraci√≥n", "texto", "diccionario",
        "traductor", "int√©rprete", "biling√ºe", "multiling√ºe",
        "idiomas", "extranjero", "nativo", "aprender", "ense√±ar",
        "hablar", "escribir", "leer", "entender", "comprender",
    ]
    return any(palabra in texto.lower() for palabra in palabras_clave)

# Funci√≥n para generar el prompt de chat incluyendo el historial y el nuevo mensaje
def generar_contexto_chat(nuevo_mensaje):
    contexto = ""
    for msg in st.session_state.messages:
        rol = "Usuario" if msg["role"] == "user" else "Asistente"
        contexto += f"{rol}: {msg['content']}\n"
    contexto += f"Usuario: {nuevo_mensaje}\nAsistente:"
    return contexto

# Chat en tiempo real
st.subheader("üí¨ Chat en tiempo real")

if "messages" not in st.session_state:
    st.session_state.messages = []

# Mostrar historial de mensajes
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Escribe tu mensaje..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Si es el primer mensaje de la conversaci√≥n, se aplica el filtro de temas ling√º√≠sticos.
    if len(st.session_state.messages) == 1:
        if not es_relacionado_con_lenguaje(prompt):
            respuesta_no = "Lo siento, solo respondo consultas relacionadas con el lenguaje."
            st.session_state.messages.append({"role": "assistant", "content": respuesta_no})
            with st.chat_message("assistant"):
                st.markdown(respuesta_no)
        else:
            prompt_contexto = generar_contexto_chat(prompt)
            try:
                model = genai.GenerativeModel("gemini-1.5-pro-latest")
                response = model.generate_content(prompt_contexto)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
                with st.chat_message("assistant"):
                    st.markdown(response.text)
            except Exception as e:
                st.error(f"‚ùå Error al generar respuesta: {e}")
    else:
        # Si ya hay un historial, se usa el contexto completo sin aplicar nuevamente el filtro.
        prompt_contexto = generar_contexto_chat("Solo Responde si consideras que esta relacionado con un agente del lenguaje y la traducci√≥n, sino responde un mensaje generico como que no es posible porque solo sos un agente del lenguaje. Si consideras que el mensaje es apto para un agente del lenguaje hace lo siguiente:  " + prompt)
        try:
            model = genai.GenerativeModel("gemini-1.5-pro-latest")
            response = model.generate_content(prompt_contexto)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
            with st.chat_message("assistant"):
                st.markdown(response.text)
        except Exception as e:
            st.error(f"‚ùå Error al generar respuesta: {e}")